apiVersion: v1
kind: ConfigMap
metadata:
  namespace: {{ .Values.namespace }}
  name: flink-config
  labels:
    app: {{ template "name"  . }}
data:
  flink-conf.yaml: |+
    jobmanager.rpc.address: {{ template "name" . }}-jobmanager
    taskmanager.numberOfTaskSlots: {{ .Values.flink.num_slots_per_taskmanager }}
    blob.server.port: 6124
    jobmanager.rpc.port: 6123
    taskmanager.rpc.port: 6122
    queryable-state.proxy.ports: 6125
    jobmanager.memory.process.size: {{ .Values.flink.jobmanager_memory_process_size }}
    taskmanager.memory.process.size: {{ .Values.flink.taskmanager_memory_process_size }}
    kubernetes.namespace: {{ .Values.namespace }}
    parallelism.default: {{ .Values.flink.num_slots_per_taskmanager }}
    kubernetes.taskmanager.cpu: {{ .Values.flink.num_slots_per_taskmanager }}
    kubernetes.jobmanager.cpu: 1.0

    # Below configuration will be used for K8s HA 
    kubernetes.cluster-id: {{ template "name" . }}-cluster
    high-availability: org.apache.flink.kubernetes.highavailability.KubernetesHaServicesFactory
    restart-strategy: fixed-delay
    restart-strategy.fixed-delay.attempts: 10
    high-availability.storageDir: {{ .Values.flink.storage.high_availability_storageDir }}
    state.savepoints.dir: {{ .Values.flink.storage.state_savepoints_dir }}
    jobmanager.archive.fs.dir: {{ .Values.flink.storage.jobmanager_archive_fs_dir }}
    web.upload.dir: {{ .Values.flink.storage.web_upload_dir }}
    # Monitor the following directories for completed jobs
    historyserver.archive.fs.dir: {{ .Values.flink.storage.jobmanager_archive_fs_dir }}
    # Refresh every 10 seconds
    historyserver.archive.fs.refresh-interval: 10000

    #fs.s3a.access.key: {{ .Values.flink.storage.fs_s3a_access_key }}
    #fs.s3a.secret.key: {{ .Values.flink.storage.fs_s3a_secret_key }}

  log4j-console.properties: |+
    # This affects logging for both user code and Flink
    rootLogger.level = INFO
    rootLogger.appenderRef.console.ref = ConsoleAppender
    rootLogger.appenderRef.rolling.ref = RollingFileAppender

    # Uncomment this if you want to _only_ change Flink's logging
    #logger.flink.name = org.apache.flink
    #logger.flink.level = INFO

    # The following lines keep the log level of common libraries/connectors on
    # log level INFO. The root logger does not override this. You have to manually
    # change the log levels here.
    logger.akka.name = akka
    logger.akka.level = INFO
    logger.kafka.name= org.apache.kafka
    logger.kafka.level = INFO
    logger.hadoop.name = org.apache.hadoop
    logger.hadoop.level = INFO

    # Log all infos to the console
    appender.console.name = ConsoleAppender
    appender.console.type = CONSOLE
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n

    # Log all infos in the given rolling file
    appender.rolling.name = RollingFileAppender
    appender.rolling.type = RollingFile
    appender.rolling.append = false
    appender.rolling.fileName = ${sys:log.file}
    appender.rolling.filePattern = ${sys:log.file}.%i
    appender.rolling.layout.type = PatternLayout
    appender.rolling.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n
    appender.rolling.policies.type = Policies
    appender.rolling.policies.size.type = SizeBasedTriggeringPolicy
    appender.rolling.policies.size.size=50MB
    appender.rolling.strategy.type = DefaultRolloverStrategy
    appender.rolling.strategy.max = 10

    # Suppress the irrelevant (wrong) warnings from the Netty channel handler
    logger.netty.name = org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline
    logger.netty.level = OFF